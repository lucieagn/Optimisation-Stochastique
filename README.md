# Optimisation par Descente de Gradient Stochastique (SGD)

## Probl√®me d'optimisation

Nous cherchons √† minimiser une fonction de co√ªt d√©finie comme une esp√©rance :

$$
f(x) = \mathbb{E}[F(x, \xi)]
$$

o√π la fonction cible est donn√©e par :

$$
F(x, \xi) = (x - \xi)^2 + \sin(x - \xi) + e^{-\xi}(x^2 - 2x + 1)
$$

avec $\xi$ suivant une loi normale : $\xi \sim \mathcal{N}(\mu, \sigma^2)$.

La solution th√©orique $x^*$ est le minimum global de $f(x)$. Nous utilisons l'algorithme **SGD** (Stochastic Gradient Descent) pour approximer cette solution.

## Gradient Stochastique

Le gradient de $F(x, \xi)$ est donn√© par :

$$
\nabla F(x, \xi) = 2(x - \xi) + \cos(x - \xi) + e^{-\xi}(2x - 2)
$$

√Ä chaque it√©ration $n$, la mise √† jour de $x$ suit la r√®gle :

$$
x_{n+1} = x_n - \gamma_n \nabla F(x_n, \xi_n)
$$

avec :
- $\gamma_n$ un pas d'apprentissage,
- $\xi_n$ un √©chantillon al√©atoire ind√©pendant.

Nous choisissons une s√©quence de pas satisfaisant les conditions de Robbins-Siegmund :

$$
\sum_{n=1}^\infty \gamma_n = \infty, \quad \sum_{n=1}^\infty \gamma_n^2 < \infty
$$

avec :

$$
\gamma_n = \frac{\gamma_0}{1 + n^\alpha}, \quad \alpha \in [0.5, 1]
$$

## Approximations et Visualisations

Nous approximons $f(x)$ par une moyenne empirique :

$$
f(x) \approx \frac{1}{N} \sum_{i=1}^{N} F(x, \xi_i)
$$

et son gradient :

$$
\nabla f(x) \approx \frac{1}{N} \sum_{i=1}^{N} \nabla F(x, \xi_i)
$$

Le z√©ro du gradient correspond aux points critiques de la fonction.

Nous simulons plusieurs valeurs de $\xi$ pour observer la variance du gradient stochastique et la difficult√© d'approximation par SGD :

$$
\text{Var}(\nabla F(x, \xi))
$$

Nous analysons aussi l'influence de $\xi$ sur $F(x, \xi)$ en le fixant √† certaines valeurs typiques ($\mu$, $\mu \pm \sigma$, $\mu \pm 2\sigma$).

## Convergence et Analyse Th√©orique

Le th√©or√®me de Robbins-Siegmund garantit que sous certaines conditions :

1. $\|x_{n+1} - x_n\| \to 0$ presque s√ªrement.
2. La suite $L(x_n)$ converge presque s√ªrement vers une limite $L_\infty$.

Nous utilisons la fonction de Lyapunov suivante :

$$
L(x_n) = \frac{1}{2} (x_n - x^*)^2
$$

et analysons l'√©volution de $L(x_n)$ au cours des it√©rations.

Nous utilisons √©galement l'expression suivante pour estimer l'erreur totale :

$$
\frac{1}{\Gamma(1 + CL \gamma_k^2)} \left( CL \sum_{k \geq n+2} \gamma_k^2 + \frac{CL \gamma_{n+1}^2}{1 + CL \gamma_{n+1}^2} \right)
$$

avec :
- $CL$ une constante positive,
- Le premier terme mesurant l'impact imm√©diat du bruit stochastique,
- Le second terme repr√©sentant l'effet cumul√© des it√©rations futures.

## Param√®tres de Simulation

- **Distribution de $\xi$** : $\mathcal{N}(2,1)$
- **Param√®tres du pas** : $\gamma_n = \frac{1}{n^{0.7}}$
- **Nombre d'it√©rations** : $N_0 = 1000$
- **Constante de Lyapunov** : $CL = 1.0$

## Impl√©mentation

Le projet inclut :
- Une impl√©mentation de **SGD** pour minimiser $f(x)$,
- Des visualisations de la fonction de co√ªt et du gradient,
- Une analyse de la convergence bas√©e sur Robbins-Siegmund,
- Une √©tude des variations de $F(x, \xi)$ en fonction de $\xi$.

---

üöÄ **Ce projet permet de mieux comprendre la convergence de SGD en pr√©sence de bruit et de v√©rifier exp√©rimentalement les conditions th√©oriques de Robbins-Siegmund.**

